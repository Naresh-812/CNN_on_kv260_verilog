{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a063ada3",
   "metadata": {},
   "source": [
    "## 1. Load Model\n",
    "Load the CNN model with trained weight and bias from the .pt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbabb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf3d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN class\n",
    "class CNN(nn.Module):\n",
    "     # Initialization\n",
    "    def __init__(self):\n",
    "        super (CNN, self).__init__()\n",
    "        \n",
    "        self.conv1_out_np = np.zeros((1, 3, 24, 24))\n",
    "        self.mp1_out_np = np.zeros((1, 3, 12, 12))\n",
    "        self.conv2_out_np = np.zeros((1, 3, 8, 8))\n",
    "        self.mp2_out_np = np.zeros((1, 3, 4, 4))\n",
    "        self.fc_in_np = np.zeros((1, 48))\n",
    "        self.fc_out_np = np.zeros((1, 10))\n",
    "        \n",
    "        # 1st Convolution Layer\n",
    "        # Image Input Shape -> (28, 28, 1)\n",
    "        # Convolution Layer -> (24, 24, 3)\n",
    "        # Pooling Max Layer -> (12, 12, 3)\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5)\n",
    "        \n",
    "        # 2nd Convolution Layer\n",
    "        # Image Input Shape -> (12, 12, 3)\n",
    "        # Convolution Layer -> (8, 8, 3)\n",
    "        # pooling Max Layer -> (4, 4, 3)\n",
    "        self.conv2 = nn.Conv2d(3, 3, kernel_size=5)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        # Num of Weight = 480\n",
    "        self.fc_1 = nn.Linear(48, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        \n",
    "        # Layer Integration\n",
    "        x = self.conv1(x)\n",
    "        self.conv1_out_np = x.detach().numpy()\n",
    "        \n",
    "        x = F.relu(self.mp(x))\n",
    "        self.mp1_out_np = x.detach().numpy()\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        self.conv2_out_np = x.detach().numpy()\n",
    "        \n",
    "        x = F.relu(self.mp(x))\n",
    "        self.mp2_out_np = x.detach().numpy()\n",
    "        \n",
    "        # Flatten Layer\n",
    "        x = x.view(in_size, -1)\n",
    "        self.fc_in_np = x.detach().numpy()\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        x = self.fc_1(x)\n",
    "        self.fc_out_np = x.detach().numpy()\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a2c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc_1): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = torch.load(\"/home/ubuntu/workspace/cnn_mnist.pt\", weights_only=False)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f8050",
   "metadata": {},
   "source": [
    "## 2. Testing using Bitmap Image in SW\n",
    "Test the model (SW) to classify a digit from .bmp image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cff70ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3af67d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xffff67ade140>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get bitmap data\n",
    "img = Image.open(\"/home/ubuntu/workspace/bmp/train_0.bmp\", \"r\")\n",
    "np_img = np.array(img)\n",
    "pyplot.imshow(np_img, cmap=pyplot.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d53ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data input\n",
    "np_img_re_sw = np.reshape(np_img, (1,1,28,28))\n",
    "data = Variable(torch.tensor((np_img_re_sw / 255), dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce3ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: 5\n"
     ]
    }
   ],
   "source": [
    "# Output of feedforwarding\n",
    "output = model(data)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "print('Predicted output: ' + ', '.join(map(str, pred.flatten().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64edc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87da9575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used for SW CNN: 0.015293598175048828s\n"
     ]
    }
   ],
   "source": [
    "# Calculate computation time for SW based CNN\n",
    "t1 = time()\n",
    "output = model(data)\n",
    "t2 = time()\n",
    "t_diff_sw = t2 - t1\n",
    "print('Time used for SW CNN: {}s'.format(t_diff_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8e193",
   "metadata": {},
   "source": [
    "## 3. Program Bitstream\n",
    "Program the bitstream to the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7954ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import MMIO\n",
    "from pynq import allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a0b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Program bitstream to FPGA\n",
    "overlay = Overlay('/home/ubuntu/workspace/cnn_mnist.bit')\n",
    "\n",
    "# Access to AXI DMA\n",
    "dma = overlay.axi_dma_0\n",
    "dma_send = overlay.axi_dma_0.sendchannel\n",
    "dma_recv = overlay.axi_dma_0.recvchannel\n",
    "\n",
    "# Allocate physical memory\n",
    "input_buffer = allocate(shape=(784,), dtype=np.uint8)\n",
    "output_buffer = allocate(shape=(1,), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b526e4",
   "metadata": {},
   "source": [
    "## 4. Testing using Bitmap Image in HW\n",
    "Test the HW accelerator to classify a digit from .bmp image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782425b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input to physical memory\n",
    "np_img_re_hw = np.reshape(np_img, (1,1,1,784))\n",
    "for i in range(784):\n",
    "    input_buffer[i] = np_img_re_hw[0][0][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f25fb42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: 5\n"
     ]
    }
   ],
   "source": [
    "# Do AXI DMA transfer\n",
    "dma_send.transfer(input_buffer)\n",
    "dma_recv.transfer(output_buffer)\n",
    "print(\"Predicted output: %d\" % (output_buffer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1397cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used for HW CNN: 0.0009090900421142578s\n"
     ]
    }
   ],
   "source": [
    "# Calculate computation time for HW accelerator CNN\n",
    "t1 = time()\n",
    "dma_send.transfer(input_buffer)\n",
    "dma_recv.transfer(output_buffer)\n",
    "t2 = time()\n",
    "t_diff_hw = t2 - t1\n",
    "print('Time used for HW CNN: {}s'.format(t_diff_hw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81775391",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "Calculate the speedup factor for the HW accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb36002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware acceleration speed up: 16.8x\n"
     ]
    }
   ],
   "source": [
    "print('Hardware acceleration speed up: {:.1f}x'.format(t_diff_sw/t_diff_hw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fd6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
